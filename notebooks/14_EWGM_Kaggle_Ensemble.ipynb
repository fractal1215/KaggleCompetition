{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model: Weighted Geometric Mean + Seasonal Bump\n",
    "\n",
    "This notebook combines two approaches:\n",
    "1. Weighted Geometric Mean with exponential decay\n",
    "2. Simple seasonality bump approach\n",
    "\n",
    "Final predictions are an ensemble of both methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION SECTION\n",
    "# ============================================================\n",
    "\n",
    "# Data Paths\n",
    "DATA_PATH = Path(\"/kaggle/input/china-real-estate-demand-prediction\")\n",
    "\n",
    "# Method 1: Weighted Geometric Mean Configuration\n",
    "CONFIG_METHOD1 = {\n",
    "    'n_lags': 6,          # Number of months to look back\n",
    "    'alpha': 0.5,         # Exponential decay parameter (0 < alpha < 1)\n",
    "    't2': 6,              # Months to check for baseline condition (zero-handling)\n",
    "}\n",
    "\n",
    "# Method 2: Seasonality Bump Configuration\n",
    "CONFIG_METHOD2 = {\n",
    "    'n_lags': 7,          # Number of months to look back\n",
    "    'alpha': 0.5,         # Exponential decay parameter\n",
    "    't2': 6,              # Months to check for baseline condition\n",
    "    'clip_low': 0.85,     # Lower bound for December multiplier\n",
    "    'clip_high': 1.40,    # Upper bound for December multiplier\n",
    "}\n",
    "\n",
    "# Ensemble Configuration\n",
    "CONFIG_ENSEMBLE = {\n",
    "    'weight_method1': 0.30,    # Weight for Weighted Geometric Mean\n",
    "    'weight_method2': 0.70,    # Weight for Seasonality Bump\n",
    "}\n",
    "\n",
    "# Output\n",
    "OUTPUT_FILENAME = 'submission.csv'\n",
    "\n",
    "# Display configuration\n",
    "print(\"=\" * 60)\n",
    "print(\"ENSEMBLE MODEL CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nMethod 1 - Weighted Geometric Mean:\")\n",
    "for key, value in CONFIG_METHOD1.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nMethod 2 - Seasonality Bump:\")\n",
    "for key, value in CONFIG_METHOD2.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nEnsemble Weights:\")\n",
    "for key, value in CONFIG_ENSEMBLE.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nOutput:\")\n",
    "print(f\"  filename: {OUTPUT_FILENAME}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_nht = pd.read_csv(DATA_PATH / \"train\" / \"new_house_transactions.csv\")\n",
    "test = pd.read_csv(DATA_PATH / \"test.csv\")\n",
    "\n",
    "# Convert month to datetime\n",
    "train_nht['month'] = pd.to_datetime(train_nht['month'])\n",
    "\n",
    "# Parse test IDs\n",
    "test_id = test.id.str.split('_', expand=True)\n",
    "test['month_text'] = test_id[0]\n",
    "test['sector'] = test_id[1]\n",
    "\n",
    "# Create month mapping\n",
    "month_codes = {\n",
    "    'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
    "    'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
    "}\n",
    "\n",
    "# Add time features\n",
    "train_nht['year'] = train_nht['month'].dt.year\n",
    "train_nht['month_num'] = train_nht['month'].dt.month\n",
    "train_nht['time'] = (train_nht['year'] - 2019) * 12 + train_nht['month_num'] - 1\n",
    "train_nht['sector_id'] = train_nht.sector.str.slice(7, None).astype(int)\n",
    "\n",
    "# Parse test data\n",
    "test['year'] = test['month_text'].str.slice(0, 4).astype(int)\n",
    "test['month_abbr'] = test['month_text'].str.slice(5, None)\n",
    "test['month_num'] = test['month_abbr'].map(month_codes)\n",
    "test['time'] = (test['year'] - 2019) * 12 + test['month_num'] - 1\n",
    "test['sector_id'] = test.sector.str.slice(7, None).astype(int)\n",
    "\n",
    "print(f\"Training data: {train_nht.shape}\")\n",
    "print(f\"Test data: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Amount Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table: time x sector_id\n",
    "amount_matrix = train_nht.set_index(['time', 'sector_id']).amount_new_house_transactions.unstack()\n",
    "amount_matrix = amount_matrix.fillna(0)\n",
    "\n",
    "# Add sector 95 (missing in training)\n",
    "amount_matrix[95] = 0\n",
    "amount_matrix = amount_matrix[np.arange(1, 97)]\n",
    "\n",
    "print(f\"Amount matrix shape: {amount_matrix.shape}\")\n",
    "print(f\"Time range: {amount_matrix.index.min()} to {amount_matrix.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Method 1: Weighted Geometric Mean (Exponential Decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_geometric_mean_prediction(amount_matrix, n_lags=6, alpha=0.5, t2=6):\n",
    "    \"\"\"\n",
    "    Weighted geometric mean with exponential decay\n",
    "    \n",
    "    Parameters:\n",
    "    - n_lags: number of months to use\n",
    "    - alpha: exponential decay parameter (0.5 works best)\n",
    "    - t2: months to check for baseline condition\n",
    "    \"\"\"\n",
    "    # Generate exponential weights\n",
    "    weights = np.array([alpha**(n_lags-1-i) for i in range(n_lags)])\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    print(f\"Weighted Geometric Mean:\")\n",
    "    print(f\"  Lags: {n_lags}, Alpha: {alpha}, Weights: {weights.round(3)}\")\n",
    "    \n",
    "    # Create prediction dataframe for test period (months 67-78)\n",
    "    predictions = pd.DataFrame(index=np.arange(67, 79), columns=amount_matrix.columns, dtype=float)\n",
    "    \n",
    "    for sector in amount_matrix.columns:\n",
    "        # Check baseline condition\n",
    "        if (amount_matrix.tail(t2)[sector].min() == 0) or (amount_matrix[sector].sum() == 0):\n",
    "            predictions[sector] = 0\n",
    "            continue\n",
    "        \n",
    "        # Get recent values\n",
    "        recent_vals = amount_matrix.tail(n_lags)[sector].values\n",
    "        \n",
    "        if len(recent_vals) == n_lags and (recent_vals > 0).any():\n",
    "            # Only use positive values\n",
    "            positive_mask = recent_vals > 0\n",
    "            positive_vals = recent_vals[positive_mask]\n",
    "            corresponding_weights = weights[positive_mask]\n",
    "            \n",
    "            if len(positive_vals) > 0:\n",
    "                # Renormalize weights\n",
    "                corresponding_weights = corresponding_weights / corresponding_weights.sum()\n",
    "                \n",
    "                # Weighted geometric mean: exp(sum(wi * log(xi)))\n",
    "                log_vals = np.log(positive_vals)\n",
    "                weighted_log_mean = np.sum(corresponding_weights * log_vals) / corresponding_weights.sum()\n",
    "                weighted_geom_mean = np.exp(weighted_log_mean)\n",
    "                \n",
    "                predictions[sector] = weighted_geom_mean\n",
    "            else:\n",
    "                predictions[sector] = 0\n",
    "        else:\n",
    "            predictions[sector] = 0\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Generate Method 1 predictions\n",
    "method1_predictions = weighted_geometric_mean_prediction(\n",
    "    amount_matrix, \n",
    "    n_lags=CONFIG_METHOD1['n_lags'], \n",
    "    alpha=CONFIG_METHOD1['alpha'], \n",
    "    t2=CONFIG_METHOD1['t2']\n",
    ")\n",
    "print(f\"Method 1 predictions shape: {method1_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Method 2: Seasonality Bump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_december_multipliers(amount_matrix, clip_low=0.85, clip_high=1.40):\n",
    "    \"\"\"Compute December seasonality multipliers\"\"\"\n",
    "    is_december = (amount_matrix.index.values % 12) == 11\n",
    "    dec_means = amount_matrix[is_december].mean(axis=0)\n",
    "    nondec_means = amount_matrix[~is_december].mean(axis=0)\n",
    "    dec_counts = amount_matrix[is_december].notna().sum(axis=0)\n",
    "    \n",
    "    raw_mult = dec_means / (nondec_means + 1e-9)\n",
    "    overall_mult = float(dec_means.mean() / (nondec_means.mean() + 1e-9))\n",
    "    \n",
    "    raw_mult = raw_mult.where(dec_counts >= 1, overall_mult)\n",
    "    raw_mult = raw_mult.replace([np.inf, -np.inf], 1.0).fillna(1.0)\n",
    "    clipped_mult = raw_mult.clip(lower=clip_low, upper=clip_high)\n",
    "    \n",
    "    return clipped_mult.to_dict()\n",
    "\n",
    "def ewgm_per_sector(amount_matrix, sector, n_lags, alpha):\n",
    "    \"\"\"Exponential weighted geometric mean for one sector\"\"\"\n",
    "    weights = np.array([alpha**(n_lags - 1 - i) for i in range(n_lags)], dtype=float)\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    recent_vals = amount_matrix.tail(n_lags)[sector].values\n",
    "    if (len(recent_vals) != n_lags) or (recent_vals <= 0).all():\n",
    "        return 0.0\n",
    "    \n",
    "    mask = recent_vals > 0\n",
    "    pos_vals = recent_vals[mask]\n",
    "    pos_w = weights[mask]\n",
    "    \n",
    "    if pos_vals.size == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    pos_w = pos_w / pos_w.sum()\n",
    "    log_vals = np.log(pos_vals + 1e-12)\n",
    "    wlm = np.sum(pos_w * log_vals) / pos_w.sum()\n",
    "    return float(np.exp(wlm))\n",
    "\n",
    "def seasonal_bump_prediction(amount_matrix, n_lags=7, alpha=0.5, t2=6):\n",
    "    \"\"\"Seasonality bump method\"\"\"\n",
    "    print(f\"Seasonality Bump Method:\")\n",
    "    print(f\"  Lags: {n_lags}, Alpha: {alpha}\")\n",
    "    \n",
    "    # Base predictions\n",
    "    predictions = pd.DataFrame(index=np.arange(67, 79), columns=amount_matrix.columns, dtype=float)\n",
    "    \n",
    "    for sector in amount_matrix.columns:\n",
    "        if (amount_matrix.tail(t2)[sector].min() == 0) or (amount_matrix[sector].sum() == 0):\n",
    "            predictions[sector] = 0.0\n",
    "            continue\n",
    "        \n",
    "        base = ewgm_per_sector(amount_matrix, sector, n_lags, alpha)\n",
    "        predictions[sector] = base\n",
    "    \n",
    "    # Apply December multipliers\n",
    "    dec_multipliers = compute_december_multipliers(amount_matrix)\n",
    "    dec_rows = [t for t in predictions.index.values if (t % 12) == 11]\n",
    "    \n",
    "    if len(dec_rows) > 0:\n",
    "        for sector in predictions.columns:\n",
    "            m = dec_multipliers.get(sector, 1.0)\n",
    "            predictions.loc[dec_rows, sector] = predictions.loc[dec_rows, sector] * m\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Generate Method 2 predictions\n",
    "method2_predictions = seasonal_bump_prediction(\n",
    "    amount_matrix, \n",
    "    n_lags=CONFIG_METHOD2['n_lags'], \n",
    "    alpha=CONFIG_METHOD2['alpha'], \n",
    "    t2=CONFIG_METHOD2['t2']\n",
    ")\n",
    "print(f\"Method 2 predictions shape: {method2_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble(method1_preds, method2_preds, weight1=0.45, weight2=0.55):\n",
    "    \"\"\"\n",
    "    Create weighted ensemble of two prediction methods\n",
    "    \n",
    "    Parameters:\n",
    "    - weight1: weight for method 1 (weighted geometric mean)\n",
    "    - weight2: weight for method 2 (seasonality bump)\n",
    "    \"\"\"\n",
    "    print(f\"\\nEnsemble Weights:\")\n",
    "    print(f\"  Method 1 (Weighted Geom Mean): {weight1:.2f}\")\n",
    "    print(f\"  Method 2 (Seasonality Bump): {weight2:.2f}\")\n",
    "    \n",
    "    ensemble_preds = weight1 * method1_preds + weight2 * method2_preds\n",
    "    return ensemble_preds\n",
    "\n",
    "# Create ensemble with optimal weights\n",
    "ensemble_predictions = create_ensemble(\n",
    "    method1_predictions, \n",
    "    method2_predictions, \n",
    "    weight1=CONFIG_ENSEMBLE['weight_method1'], \n",
    "    weight2=CONFIG_ENSEMBLE['weight_method2']\n",
    ")\n",
    "\n",
    "print(f\"\\nEnsemble statistics:\")\n",
    "print(f\"  Min: {ensemble_predictions.min().min():,.0f}\")\n",
    "print(f\"  Max: {ensemble_predictions.max().max():,.0f}\")\n",
    "print(f\"  Mean: {ensemble_predictions.mean().mean():,.0f}\")\n",
    "print(f\"  Median: {ensemble_predictions.median().median():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to submission format\n",
    "submission = test.copy()\n",
    "\n",
    "# Map predictions to test set\n",
    "prediction_values = []\n",
    "for _, row in test.iterrows():\n",
    "    time_idx = row['time']\n",
    "    sector_id = row['sector_id']\n",
    "    pred_value = ensemble_predictions.loc[time_idx, sector_id]\n",
    "    prediction_values.append(pred_value)\n",
    "\n",
    "submission['new_house_transaction_amount'] = prediction_values\n",
    "\n",
    "# Save submission\n",
    "submission[['id', 'new_house_transaction_amount']].to_csv(OUTPUT_FILENAME, index=False)\n",
    "\n",
    "print(f\"\\n✅ Ensemble submission created successfully!\")\n",
    "print(f\"Saved to: {OUTPUT_FILENAME}\")\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(f\"\\nFirst few predictions:\")\n",
    "print(submission[['id', 'new_house_transaction_amount']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analysis & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare methods\n",
    "comparison = pd.DataFrame({\n",
    "    'Method 1 (WGM)': method1_predictions.values.flatten(),\n",
    "    'Method 2 (Seasonal)': method2_predictions.values.flatten(),\n",
    "    'Ensemble': ensemble_predictions.values.flatten()\n",
    "})\n",
    "\n",
    "print(\"\\nMethod Comparison:\")\n",
    "print(comparison.describe())\n",
    "\n",
    "print(f\"\\nCorrelation between methods:\")\n",
    "print(comparison.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This ensemble combines:\n",
    "- **Method 1**: Weighted Geometric Mean with exponential decay (α=0.5)\n",
    "  - Emphasizes recent trends\n",
    "  - Weight: 30%\n",
    "\n",
    "- **Method 2**: Seasonality Bump\n",
    "  - Captures December peaks\n",
    "  - Uses 7-month lag window\n",
    "  - Weight: 70%\n",
    "\n",
    "The ensemble leverages the strengths of both approaches for robust predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
