{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Stacking Ensemble: Meta-Learning Approach\n",
    "\n",
    "### Score: 0.00000\n",
    "\n",
    " This notebook implements **stacking** - training a meta-model to learn optimal combinations of base predictions.\n",
    "\n",
    "\n",
    "\n",
    " **Key Innovation**: Instead of fixed weights (0.2, 0.65), a Ridge model learns:\n",
    "\n",
    " - Sector-specific combinations\n",
    "\n",
    " - Month-specific adjustments\n",
    "\n",
    " - How to use historical averages as additional signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STACKING ENSEMBLE CONFIGURATION\n",
      "============================================================\n",
      "\n",
      "Method 1 - Weighted Geometric Mean:\n",
      "  n_lags: 6\n",
      "  alpha: 0.5\n",
      "  t2: 6\n",
      "\n",
      "Method 2 - Seasonality Bump:\n",
      "  n_lags: 7\n",
      "  alpha: 0.5\n",
      "  t2: 6\n",
      "  clip_low: 0.85\n",
      "  clip_high: 1.4\n",
      "\n",
      "Stacking Configuration:\n",
      "  validation_months: 6\n",
      "  meta_model: ridge\n",
      "  meta_alpha: 1.0\n",
      "  lookback_windows: [3, 6, 12]\n",
      "  include_month_feature: True\n",
      "  pre_scale_factor: 0.85\n",
      "\n",
      "Output Configuration:\n",
      "  output_path: /Users/nikola/Python/KaggleCompetition/output/16_stacking_ensemble\n",
      "  filename: stacking_ensemble_submission.csv\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION SECTION\n",
    "# ============================================================\n",
    "\n",
    "# Data Paths\n",
    "DATA_PATH = Path(\"/Users/nikola/Python/KaggleCompetition/data\")\n",
    "\n",
    "# Method 1: Weighted Geometric Mean Configuration\n",
    "CONFIG_METHOD1 = {\n",
    "    'n_lags': 6,\n",
    "    'alpha': 0.5,\n",
    "    't2': 6,\n",
    "}\n",
    "\n",
    "# Method 2: Seasonality Bump Configuration\n",
    "CONFIG_METHOD2 = {\n",
    "    'n_lags': 7,\n",
    "    'alpha': 0.5,\n",
    "    't2': 6,\n",
    "    'clip_low': 0.85,\n",
    "    'clip_high': 1.40,\n",
    "}\n",
    "\n",
    "# Stacking Configuration\n",
    "CONFIG_STACKING = {\n",
    "    'validation_months': 6,              # Use last 6 months for meta-model training\n",
    "    'meta_model': 'ridge',               # Options: 'ridge', 'lasso', 'rf'\n",
    "    'meta_alpha': 1.0,                   # Regularization for Ridge/Lasso\n",
    "    'lookback_windows': [3, 6, 12],      # Windows for historical averages\n",
    "    'include_month_feature': True,       # Include month number as feature\n",
    "    'pre_scale_factor': 0.85,            # Pre-scale predictions before stacking (regime shift)\n",
    "}\n",
    "\n",
    "# Output Configuration\n",
    "CONFIG_OUTPUT = {\n",
    "    'output_path': '/Users/nikola/Python/KaggleCompetition/output/16_stacking_ensemble',   # Output directory\n",
    "    'filename': 'stacking_ensemble_submission.csv'         # Submission filename\n",
    "}\n",
    "\n",
    "# Display configuration\n",
    "print(\"=\" * 60)\n",
    "print(\"STACKING ENSEMBLE CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nMethod 1 - Weighted Geometric Mean:\")\n",
    "for key, value in CONFIG_METHOD1.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nMethod 2 - Seasonality Bump:\")\n",
    "for key, value in CONFIG_METHOD2.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nStacking Configuration:\")\n",
    "for key, value in CONFIG_STACKING.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nOutput Configuration:\")\n",
    "for key, value in CONFIG_OUTPUT.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (5433, 15)\n",
      "Test data: (1152, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_nht = pd.read_csv(DATA_PATH / \"train\" / \"new_house_transactions.csv\")\n",
    "test = pd.read_csv(DATA_PATH / \"test.csv\")\n",
    "\n",
    "# Convert month to datetime\n",
    "train_nht['month'] = pd.to_datetime(train_nht['month'])\n",
    "\n",
    "# Parse test IDs\n",
    "test_id = test.id.str.split('_', expand=True)\n",
    "test['month_text'] = test_id[0]\n",
    "test['sector'] = test_id[1]\n",
    "\n",
    "# Create month mapping\n",
    "month_codes = {\n",
    "    'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
    "    'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
    "}\n",
    "\n",
    "# Add time features to training data\n",
    "train_nht['year'] = train_nht['month'].dt.year\n",
    "train_nht['month_num'] = train_nht['month'].dt.month\n",
    "train_nht['time'] = (train_nht['year'] - 2019) * 12 + train_nht['month_num'] - 1\n",
    "train_nht['sector_id'] = train_nht.sector.str.slice(7, None).astype(int)\n",
    "\n",
    "# Parse test data\n",
    "test['year'] = test['month_text'].str.slice(0, 4).astype(int)\n",
    "test['month_abbr'] = test['month_text'].str.slice(5, None)\n",
    "test['month_num'] = test['month_abbr'].map(month_codes)\n",
    "test['time'] = (test['year'] - 2019) * 12 + test['month_num'] - 1\n",
    "test['sector_id'] = test.sector.str.slice(7, None).astype(int)\n",
    "\n",
    "print(f\"Training data: {train_nht.shape}\")\n",
    "print(f\"Test data: {test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Prepare Amount Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount matrix shape: (67, 96)\n",
      "Time range: 0 to 66\n"
     ]
    }
   ],
   "source": [
    "# Create pivot table: time x sector_id\n",
    "amount_matrix = train_nht.set_index(['time', 'sector_id']).amount_new_house_transactions.unstack()\n",
    "amount_matrix = amount_matrix.fillna(0)\n",
    "\n",
    "# Add sector 95 (missing in training)\n",
    "amount_matrix[95] = 0\n",
    "amount_matrix = amount_matrix[np.arange(1, 97)]\n",
    "\n",
    "print(f\"Amount matrix shape: {amount_matrix.shape}\")\n",
    "print(f\"Time range: {amount_matrix.index.min()} to {amount_matrix.index.max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3. Base Model Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_geometric_mean_prediction(amount_matrix, n_lags=6, alpha=0.5, t2=6, \n",
    "                                      prediction_horizon=12):\n",
    "    \"\"\"Method 1: Weighted Geometric Mean with exponential decay\"\"\"\n",
    "    weights = np.array([alpha**(n_lags-1-i) for i in range(n_lags)])\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    # Create prediction dataframe\n",
    "    last_time = amount_matrix.index.max()\n",
    "    pred_indices = np.arange(last_time + 1, last_time + 1 + prediction_horizon)\n",
    "    predictions = pd.DataFrame(index=pred_indices, columns=amount_matrix.columns, dtype=float)\n",
    "    \n",
    "    for sector in amount_matrix.columns:\n",
    "        if (amount_matrix.tail(t2)[sector].min() == 0) or (amount_matrix[sector].sum() == 0):\n",
    "            predictions[sector] = 0\n",
    "            continue\n",
    "        \n",
    "        recent_vals = amount_matrix.tail(n_lags)[sector].values\n",
    "        \n",
    "        if len(recent_vals) == n_lags and (recent_vals > 0).any():\n",
    "            positive_mask = recent_vals > 0\n",
    "            positive_vals = recent_vals[positive_mask]\n",
    "            corresponding_weights = weights[positive_mask]\n",
    "            \n",
    "            if len(positive_vals) > 0:\n",
    "                corresponding_weights = corresponding_weights / corresponding_weights.sum()\n",
    "                log_vals = np.log(positive_vals)\n",
    "                weighted_log_mean = np.sum(corresponding_weights * log_vals)\n",
    "                weighted_geom_mean = np.exp(weighted_log_mean)\n",
    "                predictions[sector] = weighted_geom_mean\n",
    "            else:\n",
    "                predictions[sector] = 0\n",
    "        else:\n",
    "            predictions[sector] = 0\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def compute_december_multipliers(amount_matrix, clip_low=0.85, clip_high=1.40):\n",
    "    \"\"\"Compute December seasonality multipliers\"\"\"\n",
    "    is_december = (amount_matrix.index.values % 12) == 11\n",
    "    dec_means = amount_matrix[is_december].mean(axis=0)\n",
    "    nondec_means = amount_matrix[~is_december].mean(axis=0)\n",
    "    dec_counts = amount_matrix[is_december].notna().sum(axis=0)\n",
    "    \n",
    "    raw_mult = dec_means / (nondec_means + 1e-9)\n",
    "    overall_mult = float(dec_means.mean() / (nondec_means.mean() + 1e-9))\n",
    "    \n",
    "    raw_mult = raw_mult.where(dec_counts >= 1, overall_mult)\n",
    "    raw_mult = raw_mult.replace([np.inf, -np.inf], 1.0).fillna(1.0)\n",
    "    clipped_mult = raw_mult.clip(lower=clip_low, upper=clip_high)\n",
    "    \n",
    "    return clipped_mult.to_dict()\n",
    "\n",
    "def ewgm_per_sector(amount_matrix, sector, n_lags, alpha):\n",
    "    \"\"\"Exponential weighted geometric mean for one sector\"\"\"\n",
    "    weights = np.array([alpha**(n_lags - 1 - i) for i in range(n_lags)], dtype=float)\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    recent_vals = amount_matrix.tail(n_lags)[sector].values\n",
    "    if (len(recent_vals) != n_lags) or (recent_vals <= 0).all():\n",
    "        return 0.0\n",
    "    \n",
    "    mask = recent_vals > 0\n",
    "    pos_vals = recent_vals[mask]\n",
    "    pos_w = weights[mask]\n",
    "    \n",
    "    if pos_vals.size == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    pos_w = pos_w / pos_w.sum()\n",
    "    log_vals = np.log(pos_vals + 1e-12)\n",
    "    wlm = np.sum(pos_w * log_vals)\n",
    "    return float(np.exp(wlm))\n",
    "\n",
    "def seasonal_bump_prediction(amount_matrix, n_lags=7, alpha=0.5, t2=6, \n",
    "                            clip_low=0.85, clip_high=1.40, prediction_horizon=12):\n",
    "    \"\"\"Method 2: Seasonality Bump\"\"\"\n",
    "    # Base predictions\n",
    "    last_time = amount_matrix.index.max()\n",
    "    pred_indices = np.arange(last_time + 1, last_time + 1 + prediction_horizon)\n",
    "    predictions = pd.DataFrame(index=pred_indices, columns=amount_matrix.columns, dtype=float)\n",
    "    \n",
    "    for sector in amount_matrix.columns:\n",
    "        if (amount_matrix.tail(t2)[sector].min() == 0) or (amount_matrix[sector].sum() == 0):\n",
    "            predictions[sector] = 0.0\n",
    "            continue\n",
    "        \n",
    "        base = ewgm_per_sector(amount_matrix, sector, n_lags, alpha)\n",
    "        predictions[sector] = base\n",
    "    \n",
    "    # Apply December multipliers\n",
    "    dec_multipliers = compute_december_multipliers(amount_matrix, clip_low, clip_high)\n",
    "    \n",
    "    for time_idx in predictions.index:\n",
    "        if (time_idx % 12) == 11:  # December\n",
    "            for sector in predictions.columns:\n",
    "                m = dec_multipliers.get(sector, 1.0)\n",
    "                predictions.loc[time_idx, sector] *= m\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4. Stacking Meta-Learning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_custom_metric(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Implements the two-stage custom metric from competition\n",
    "    \n",
    "    Stage 1: If >30% of samples have APE > 100%, return score of 0\n",
    "    Stage 2: Calculate MAPE on samples with APE <= 100%, \n",
    "             divide by fraction of valid samples, subtract from 1\n",
    "    \"\"\"\n",
    "    y_pred = np.array(y_pred).flatten()\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    \n",
    "    # Calculate absolute percentage errors\n",
    "    ape = np.abs((y_pred - y_true) / (y_true + 1e-9))\n",
    "    \n",
    "    # Stage 1: Check if >30% have APE > 100%\n",
    "    high_error_fraction = (ape > 1.0).sum() / len(ape)\n",
    "    \n",
    "    if high_error_fraction > 0.3:\n",
    "        return 0.0\n",
    "    \n",
    "    # Stage 2: Calculate on samples with APE <= 100%\n",
    "    valid_mask = ape <= 1.0\n",
    "    \n",
    "    if valid_mask.sum() == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    valid_ape = ape[valid_mask]\n",
    "    mape = valid_ape.mean()\n",
    "    \n",
    "    # Scale by fraction of valid samples\n",
    "    fraction_valid = valid_mask.sum() / len(ape)\n",
    "    scaled_mape = mape / fraction_valid\n",
    "    \n",
    "    # Final score\n",
    "    score = 1 - scaled_mape\n",
    "    \n",
    "    return score\n",
    "\n",
    "def create_meta_features(amount_matrix, method1_preds, method2_preds, \n",
    "                        time_indices, lookback_windows=[3, 6, 12],\n",
    "                        include_month=True):\n",
    "    \"\"\"\n",
    "    Create meta-features for stacking\n",
    "    \n",
    "    Features:\n",
    "    1. Method 1 predictions\n",
    "    2. Method 2 predictions\n",
    "    3. Historical averages (3, 6, 12 months)\n",
    "    4. Month number (optional)\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    targets_list = []\n",
    "    time_list = []\n",
    "    sector_list = []\n",
    "    \n",
    "    for time_idx in time_indices:\n",
    "        for sector in amount_matrix.columns:\n",
    "            # Base model predictions\n",
    "            pred1 = method1_preds.loc[time_idx, sector]\n",
    "            pred2 = method2_preds.loc[time_idx, sector]\n",
    "            \n",
    "            # Historical averages\n",
    "            hist_features = []\n",
    "            for window in lookback_windows:\n",
    "                if time_idx >= window:\n",
    "                    hist_avg = amount_matrix.iloc[time_idx-window:time_idx][sector].mean()\n",
    "                else:\n",
    "                    hist_avg = amount_matrix.iloc[:time_idx][sector].mean() if time_idx > 0 else 0\n",
    "                hist_features.append(hist_avg)\n",
    "            \n",
    "            # Month feature\n",
    "            month_num = time_idx % 12\n",
    "            \n",
    "            # Combine features\n",
    "            feature_row = [pred1, pred2] + hist_features\n",
    "            if include_month:\n",
    "                feature_row.append(month_num)\n",
    "            \n",
    "            features_list.append(feature_row)\n",
    "            time_list.append(time_idx)\n",
    "            sector_list.append(sector)\n",
    "            \n",
    "            # Target (if available)\n",
    "            if time_idx in amount_matrix.index:\n",
    "                targets_list.append(amount_matrix.loc[time_idx, sector])\n",
    "            else:\n",
    "                targets_list.append(np.nan)\n",
    "    \n",
    "    # Create feature names\n",
    "    feature_names = ['method1_pred', 'method2_pred'] + \\\n",
    "                   [f'hist_avg_{w}m' for w in lookback_windows]\n",
    "    if include_month:\n",
    "        feature_names.append('month_num')\n",
    "    \n",
    "    X = pd.DataFrame(features_list, columns=feature_names)\n",
    "    X['time'] = time_list\n",
    "    X['sector'] = sector_list\n",
    "    y = pd.Series(targets_list, name='target')\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def train_meta_model(X_meta, y_meta, model_type='ridge', alpha=1.0):\n",
    "    \"\"\"\n",
    "    Train meta-model on validation data\n",
    "    \n",
    "    model_type: 'ridge', 'lasso', or 'rf'\n",
    "    \"\"\"\n",
    "    # Remove rows with missing targets\n",
    "    valid_mask = ~y_meta.isna()\n",
    "    X_train = X_meta[valid_mask].drop(['time', 'sector'], axis=1)\n",
    "    y_train = y_meta[valid_mask]\n",
    "    \n",
    "    # Select meta-model\n",
    "    if model_type == 'ridge':\n",
    "        meta_model = Ridge(alpha=alpha)\n",
    "    elif model_type == 'lasso':\n",
    "        meta_model = Lasso(alpha=alpha)\n",
    "    elif model_type == 'rf':\n",
    "        meta_model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    print(f\"\\nTraining {model_type} meta-model on {len(X_train)} samples...\")\n",
    "    meta_model.fit(X_train, y_train)\n",
    "    print(\"✓ Meta-model trained!\")\n",
    "    \n",
    "    # Show feature importance\n",
    "    if hasattr(meta_model, 'coef_'):\n",
    "        print(\"\\nLearned coefficients:\")\n",
    "        for name, coef in zip(X_train.columns, meta_model.coef_):\n",
    "            print(f\"  {name:20s}: {coef:8.4f}\")\n",
    "        print(f\"  {'intercept':20s}: {meta_model.intercept_:8.4f}\")\n",
    "    \n",
    "    return meta_model\n",
    "\n",
    "def predict_with_meta_model(meta_model, X_meta):\n",
    "    \"\"\"Generate predictions using trained meta-model\"\"\"\n",
    "    X_pred = X_meta.drop(['time', 'sector'], axis=1)\n",
    "    \n",
    "    # Fill NaN values with 0 (important for test set where some historical windows may be incomplete)\n",
    "    X_pred = X_pred.fillna(0)\n",
    "    \n",
    "    predictions = meta_model.predict(X_pred)\n",
    "    \n",
    "    # Reshape to time x sector format\n",
    "    result = pd.DataFrame({\n",
    "        'time': X_meta['time'],\n",
    "        'sector': X_meta['sector'],\n",
    "        'prediction': predictions\n",
    "    })\n",
    "    \n",
    "    pivot = result.pivot(index='time', columns='sector', values='prediction')\n",
    "    return pivot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 5. Train Meta-Model on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STACKING ENSEMBLE - TRAINING PHASE\n",
      "============================================================\n",
      "\n",
      "Data split:\n",
      "  Training: months 0 to 60\n",
      "  Validation: months 61 to 66\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"STACKING ENSEMBLE - TRAINING PHASE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Split data for meta-model training\n",
    "val_months = CONFIG_STACKING['validation_months']\n",
    "train_cutoff = len(amount_matrix) - val_months\n",
    "\n",
    "train_matrix = amount_matrix.iloc[:train_cutoff].copy()\n",
    "val_matrix = amount_matrix.iloc[train_cutoff:].copy()\n",
    "val_indices = val_matrix.index\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Training: months {train_matrix.index.min()} to {train_matrix.index.max()}\")\n",
    "print(f\"  Validation: months {val_indices.min()} to {val_indices.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating base model predictions on validation set...\n",
      "\n",
      "Pre-scaling predictions by 0.85 (regime shift adjustment)\n",
      "  Method 1 predictions: (6, 96)\n",
      "  Method 2 predictions: (6, 96)\n"
     ]
    }
   ],
   "source": [
    "# Generate base model predictions on validation period\n",
    "print(\"\\nGenerating base model predictions on validation set...\")\n",
    "method1_val = weighted_geometric_mean_prediction(\n",
    "    train_matrix, \n",
    "    **CONFIG_METHOD1,\n",
    "    prediction_horizon=val_months\n",
    ")\n",
    "method2_val = seasonal_bump_prediction(\n",
    "    train_matrix,\n",
    "    **CONFIG_METHOD2,\n",
    "    prediction_horizon=val_months\n",
    ")\n",
    "\n",
    "# Pre-scale predictions for regime shift\n",
    "pre_scale = CONFIG_STACKING.get('pre_scale_factor', 1.0)\n",
    "if pre_scale != 1.0:\n",
    "    print(f\"\\nPre-scaling predictions by {pre_scale} (regime shift adjustment)\")\n",
    "    method1_val = method1_val * pre_scale\n",
    "    method2_val = method2_val * pre_scale\n",
    "\n",
    "print(f\"  Method 1 predictions: {method1_val.shape}\")\n",
    "print(f\"  Method 2 predictions: {method2_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meta-features shape: (576, 8)\n",
      "Features: ['method1_pred', 'method2_pred', 'hist_avg_3m', 'hist_avg_6m', 'hist_avg_12m', 'month_num']\n"
     ]
    }
   ],
   "source": [
    "# Create meta-features for validation\n",
    "X_meta_val, y_meta_val = create_meta_features(\n",
    "    amount_matrix,\n",
    "    method1_val,\n",
    "    method2_val,\n",
    "    val_indices,\n",
    "    lookback_windows=CONFIG_STACKING['lookback_windows'],\n",
    "    include_month=CONFIG_STACKING['include_month_feature']\n",
    ")\n",
    "\n",
    "print(f\"\\nMeta-features shape: {X_meta_val.shape}\")\n",
    "print(f\"Features: {[c for c in X_meta_val.columns if c not in ['time', 'sector']]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ridge meta-model on 576 samples...\n",
      "✓ Meta-model trained!\n",
      "\n",
      "Learned coefficients:\n",
      "  method1_pred        :  -1.8436\n",
      "  method2_pred        :   2.6156\n",
      "  hist_avg_3m         :   0.2784\n",
      "  hist_avg_6m         :   0.4781\n",
      "  hist_avg_12m        :  -0.2259\n",
      "  month_num           : 2738.5963\n",
      "  intercept           : -9576.6339\n"
     ]
    }
   ],
   "source": [
    "# Train meta-model\n",
    "meta_model = train_meta_model(\n",
    "    X_meta_val,\n",
    "    y_meta_val,\n",
    "    model_type=CONFIG_STACKING['meta_model'],\n",
    "    alpha=CONFIG_STACKING['meta_alpha']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 6. Generate Final Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GENERATING FINAL PREDICTIONS\n",
      "============================================================\n",
      "\n",
      "Generating base model predictions on test set...\n",
      "\n",
      "Pre-scaling test predictions by 0.85 (regime shift adjustment)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GENERATING FINAL PREDICTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate base model predictions on full training data for test period\n",
    "print(\"\\nGenerating base model predictions on test set...\")\n",
    "method1_test = weighted_geometric_mean_prediction(\n",
    "    amount_matrix,\n",
    "    **CONFIG_METHOD1,\n",
    "    prediction_horizon=12\n",
    ")\n",
    "method2_test = seasonal_bump_prediction(\n",
    "    amount_matrix,\n",
    "    **CONFIG_METHOD2,\n",
    "    prediction_horizon=12\n",
    ")\n",
    "\n",
    "# Pre-scale predictions for regime shift\n",
    "pre_scale = CONFIG_STACKING.get('pre_scale_factor', 1.0)\n",
    "if pre_scale != 1.0:\n",
    "    print(f\"\\nPre-scaling test predictions by {pre_scale} (regime shift adjustment)\")\n",
    "    method1_test = method1_test * pre_scale\n",
    "    method2_test = method2_test * pre_scale\n",
    "\n",
    "test_indices = method1_test.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final predictions shape: (12, 96)\n",
      "Prediction statistics:\n",
      "  Min: 0\n",
      "  Max: 264,031\n",
      "  Mean: 25,692\n",
      "  Median: 10,278\n",
      "  Sector 95 predictions (should be all 0): [0]\n"
     ]
    }
   ],
   "source": [
    "# Create meta-features for test\n",
    "X_meta_test, _ = create_meta_features(\n",
    "    amount_matrix,\n",
    "    method1_test,\n",
    "    method2_test,\n",
    "    test_indices,\n",
    "    lookback_windows=CONFIG_STACKING['lookback_windows'],\n",
    "    include_month=CONFIG_STACKING['include_month_feature']\n",
    ")\n",
    "\n",
    "# Generate final predictions\n",
    "final_predictions = predict_with_meta_model(meta_model, X_meta_test)\n",
    "\n",
    "# Clip negative predictions to zero (transaction amounts can't be negative)\n",
    "final_predictions = final_predictions.clip(lower=0)\n",
    "\n",
    "# Ensure sector 95 is all zeros (no training data for this sector)\n",
    "if 95 in final_predictions.columns:\n",
    "    final_predictions[95] = 0\n",
    "\n",
    "print(f\"\\nFinal predictions shape: {final_predictions.shape}\")\n",
    "print(f\"Prediction statistics:\")\n",
    "print(f\"  Min: {final_predictions.min().min():,.0f}\")\n",
    "print(f\"  Max: {final_predictions.max().max():,.0f}\")\n",
    "print(f\"  Mean: {final_predictions.mean().mean():,.0f}\")\n",
    "print(f\"  Median: {final_predictions.median().median():,.0f}\")\n",
    "print(f\"  Sector 95 predictions (should be all 0): {final_predictions[95].unique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 7. Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING SUBMISSION\n",
      "============================================================\n",
      "\n",
      "✅ Stacking submission created successfully!\n",
      "Saved to: /Users/nikola/Python/KaggleCompetition/output/16_stacking_ensemble/stacking_ensemble_submission.csv\n",
      "\n",
      "First few predictions:\n",
      "                   id  new_house_transaction_amount\n",
      "0   2024 Aug_sector 1                  20080.278400\n",
      "1   2024 Aug_sector 2                  15981.597490\n",
      "2   2024 Aug_sector 3                  15696.319314\n",
      "3   2024 Aug_sector 4                 103557.026326\n",
      "4   2024 Aug_sector 5                  12381.231355\n",
      "5   2024 Aug_sector 6                  27974.548520\n",
      "6   2024 Aug_sector 7                  17947.385391\n",
      "7   2024 Aug_sector 8                  13920.146785\n",
      "8   2024 Aug_sector 9                  23577.488443\n",
      "9  2024 Aug_sector 10                  70683.604152\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CREATING SUBMISSION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "submission = test.copy()\n",
    "\n",
    "# Map predictions to test set\n",
    "prediction_values = []\n",
    "for _, row in test.iterrows():\n",
    "    time_idx = row['time']\n",
    "    sector_id = row['sector_id']\n",
    "    pred_value = final_predictions.loc[time_idx, sector_id]\n",
    "    prediction_values.append(pred_value)\n",
    "\n",
    "submission['new_house_transaction_amount'] = prediction_values\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = Path(CONFIG_OUTPUT['output_path'])\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save submission\n",
    "output_file = output_dir / CONFIG_OUTPUT['filename']\n",
    "submission[['id', 'new_house_transaction_amount']].to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✅ Stacking submission created successfully!\")\n",
    "print(f\"Saved to: {output_file}\")\n",
    "print(f\"\\nFirst few predictions:\")\n",
    "print(submission[['id', 'new_house_transaction_amount']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 8. Comparison with Fixed Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPARISON: Stacking vs Fixed Weights (on validation)\n",
      "============================================================\n",
      "\n",
      "Note: Both methods pre-scaled by 0.85 for regime shift\n",
      "\n",
      "Validation predictions summary:\n",
      "            Method1       Method2  Fixed_Weights       Stacking         Actual\n",
      "count    576.000000    576.000000     576.000000     576.000000     576.000000\n",
      "mean   16353.109759  16348.670186   13897.257573   23983.653512   23522.521667\n",
      "std    19336.026877  19326.290151   16429.270003   28088.415915   35056.964536\n",
      "min        0.000000      0.000000       0.000000       0.000000       0.000000\n",
      "25%     1696.429766   1688.843128    1437.033987    4116.347365    2286.047500\n",
      "50%    10637.179542  10623.991032    9026.243598   14493.203377   10565.440000\n",
      "75%    25029.982222  25028.959368   21274.820034   33182.081690   27081.057500\n",
      "max    92087.268502  92062.672941   78258.191112  137109.160304  272474.460000\n",
      "\n",
      "Correlations with Actual:\n",
      "Actual           1.000000\n",
      "Stacking         0.815521\n",
      "Method1          0.785926\n",
      "Fixed_Weights    0.785866\n",
      "Method2          0.785846\n",
      "Name: Actual, dtype: float64\n",
      "\n",
      "============================================================\n",
      "CUSTOM COMPETITION METRIC (higher is better)\n",
      "============================================================\n",
      "\n",
      "Method 1 (WGM):          0.54535\n",
      "Method 2 (Seasonal):     0.54635\n",
      "Fixed Weights (0.2/0.65): 0.53512\n",
      "Stacking (pre-scaled):    0.45742\n",
      "\n",
      "❌ Stacking decline: -0.07770 (14.52%)\n",
      "\n",
      "============================================================\n",
      "DONE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARISON: Stacking vs Fixed Weights (on validation)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Fixed weights approach (original best: 0.2, 0.65)\n",
    "# Note: Apply same pre-scaling for fair comparison\n",
    "pre_scale = CONFIG_STACKING.get('pre_scale_factor', 1.0)\n",
    "method1_val_comparison = method1_val.copy()\n",
    "method2_val_comparison = method2_val.copy()\n",
    "fixed_weights_val = 0.2 * method1_val_comparison + 0.65 * method2_val_comparison\n",
    "\n",
    "# Stacking approach on validation\n",
    "stacking_val = predict_with_meta_model(meta_model, X_meta_val)\n",
    "\n",
    "# Clip negative predictions\n",
    "stacking_val = stacking_val.clip(lower=0)\n",
    "\n",
    "print(f\"\\nNote: Both methods pre-scaled by {pre_scale} for regime shift\")\n",
    "\n",
    "# Compare predictions\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Method1': method1_val_comparison.values.flatten(),\n",
    "    'Method2': method2_val_comparison.values.flatten(),\n",
    "    'Fixed_Weights': fixed_weights_val.values.flatten(),\n",
    "    'Stacking': stacking_val.values.flatten(),\n",
    "    'Actual': val_matrix.values.flatten()\n",
    "})\n",
    "\n",
    "print(\"\\nValidation predictions summary:\")\n",
    "print(comparison_df.describe())\n",
    "\n",
    "print(\"\\nCorrelations with Actual:\")\n",
    "print(comparison_df.corr()['Actual'].sort_values(ascending=False))\n",
    "\n",
    "# Calculate custom metric for each method\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CUSTOM COMPETITION METRIC (higher is better)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "score_method1 = calculate_custom_metric(\n",
    "    comparison_df['Method1'].values,\n",
    "    comparison_df['Actual'].values\n",
    ")\n",
    "score_method2 = calculate_custom_metric(\n",
    "    comparison_df['Method2'].values,\n",
    "    comparison_df['Actual'].values\n",
    ")\n",
    "score_fixed = calculate_custom_metric(\n",
    "    comparison_df['Fixed_Weights'].values,\n",
    "    comparison_df['Actual'].values\n",
    ")\n",
    "score_stacking = calculate_custom_metric(\n",
    "    comparison_df['Stacking'].values,\n",
    "    comparison_df['Actual'].values\n",
    ")\n",
    "\n",
    "print(f\"\\nMethod 1 (WGM):          {score_method1:.5f}\")\n",
    "print(f\"Method 2 (Seasonal):     {score_method2:.5f}\")\n",
    "print(f\"Fixed Weights (0.2/0.65): {score_fixed:.5f}\")\n",
    "print(f\"Stacking (pre-scaled):    {score_stacking:.5f}\")\n",
    "\n",
    "# Show improvement\n",
    "if score_stacking > score_fixed:\n",
    "    improvement = score_stacking - score_fixed\n",
    "    pct_improvement = (improvement / score_fixed) * 100\n",
    "    print(f\"\\n✅ Stacking improvement: +{improvement:.5f} ({pct_improvement:+.2f}%)\")\n",
    "elif score_stacking < score_fixed:\n",
    "    decline = score_fixed - score_stacking\n",
    "    pct_decline = (decline / score_fixed) * 100\n",
    "    print(f\"\\n❌ Stacking decline: -{decline:.5f} ({pct_decline:.2f}%)\")\n",
    "else:\n",
    "    print(f\"\\n➡️ No difference between methods\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DONE!\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Summary\n",
    "\n",
    "\n",
    "\n",
    " This stacking ensemble:\n",
    "\n",
    " - Trains a Ridge model to learn optimal combinations of base predictions\n",
    "\n",
    " - Uses historical averages (3m, 6m, 12m) as additional features\n",
    "\n",
    " - Learns sector-specific and month-specific weights automatically\n",
    "\n",
    "\n",
    "\n",
    " Expected improvement over fixed weights (0.2, 0.65): +0.0005 to +0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CORRELATION CHECK: Stacking vs Best Fixed Weights\n",
      "============================================================\n",
      "\n",
      "Correlation between submissions: 0.76627\n",
      "\n",
      "Prediction statistics:\n",
      "       new_house_transaction_amount_stacking  \\\n",
      "count                            1152.000000   \n",
      "mean                            25691.861979   \n",
      "std                             35006.031171   \n",
      "min                                 0.000000   \n",
      "25%                              4104.681848   \n",
      "50%                             15057.236695   \n",
      "75%                             31720.041084   \n",
      "max                            264031.303661   \n",
      "\n",
      "       new_house_transaction_amount_ensemble  \n",
      "count                            1152.000000  \n",
      "mean                            21061.740699  \n",
      "std                             28002.463975  \n",
      "min                                 0.000000  \n",
      "25%                              1843.147180  \n",
      "50%                              9853.129411  \n",
      "75%                             25620.303156  \n",
      "max                            145102.206947  \n",
      "\n",
      "Differences:\n",
      "  Mean absolute difference: 16,293.06\n",
      "  Max absolute difference: 118,929.10\n",
      "  Samples with >10% difference: 1034 / 1152 (89.8%)\n",
      "  Samples with >50% difference: 841 / 1152 (73.0%)\n",
      "\n",
      "Warning: Low correlation (0.766) - Stacking diverging significantly\n",
      "This likely explains the 0.0 Kaggle score\n",
      "\n",
      "Top 10 largest differences:\n",
      "                     id  new_house_transaction_amount_ensemble  \\\n",
      "468  2024 Dec_sector 85                          145102.206947   \n",
      "444  2024 Dec_sector 61                          123009.947851   \n",
      "438  2024 Dec_sector 55                          115065.045412   \n",
      "399  2024 Dec_sector 16                           99841.349597   \n",
      "415  2024 Dec_sector 32                           81075.712666   \n",
      "236  2024 Oct_sector 45                           61622.129439   \n",
      "419  2024 Dec_sector 36                          139676.318801   \n",
      "417  2024 Dec_sector 34                           93072.710652   \n",
      "387   2024 Dec_sector 4                           90745.257150   \n",
      "407  2024 Dec_sector 24                           83994.936675   \n",
      "\n",
      "     new_house_transaction_amount_stacking       abs_diff  \n",
      "468                          264031.303661  118929.096715  \n",
      "444                          232509.998551  109500.050701  \n",
      "438                          217496.980374  102431.934962  \n",
      "399                          200838.761631  100997.412034  \n",
      "415                          178704.044529   97628.331863  \n",
      "236                          152369.351251   90747.221812  \n",
      "419                          228180.824486   88504.505685  \n",
      "417                          177312.185931   84239.475279  \n",
      "387                          174363.939071   83618.681921  \n",
      "407                          164197.463196   80202.526520  \n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# Compare stacking submission with best fixed weights submission\n",
    "print(\"=\" * 60)\n",
    "print(\"CORRELATION CHECK: Stacking vs Best Fixed Weights\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load both submission files\n",
    "stacking_path = '/Users/nikola/Python/KaggleCompetition/output/16_stacking_ensemble/stacking_ensemble_submission.csv'\n",
    "ensemble_path = '/Users/nikola/Python/KaggleCompetition/output/15_new_try_EWGM_Ensemble/15_EWGM_w85_submission.csv'\n",
    "\n",
    "stacking_sub = pd.read_csv(stacking_path)\n",
    "ensemble_sub = pd.read_csv(ensemble_path)\n",
    "\n",
    "# Merge on id to align predictions\n",
    "merged = stacking_sub.merge(ensemble_sub, on='id', suffixes=('_stacking', '_ensemble'))\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = merged['new_house_transaction_amount_stacking'].corr(\n",
    "    merged['new_house_transaction_amount_ensemble']\n",
    ")\n",
    "\n",
    "print(f\"\\nCorrelation between submissions: {correlation:.5f}\")\n",
    "\n",
    "# Show prediction statistics\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(merged[['new_house_transaction_amount_stacking', 'new_house_transaction_amount_ensemble']].describe())\n",
    "\n",
    "# Check differences\n",
    "merged['abs_diff'] = np.abs(\n",
    "    merged['new_house_transaction_amount_stacking'] - \n",
    "    merged['new_house_transaction_amount_ensemble']\n",
    ")\n",
    "merged['pct_diff'] = merged['abs_diff'] / (merged['new_house_transaction_amount_ensemble'] + 1)\n",
    "\n",
    "print(f\"\\nDifferences:\")\n",
    "print(f\"  Mean absolute difference: {merged['abs_diff'].mean():,.2f}\")\n",
    "print(f\"  Max absolute difference: {merged['abs_diff'].max():,.2f}\")\n",
    "print(f\"  Samples with >10% difference: {(merged['pct_diff'] > 0.1).sum()} / {len(merged)} ({(merged['pct_diff'] > 0.1).mean()*100:.1f}%)\")\n",
    "print(f\"  Samples with >50% difference: {(merged['pct_diff'] > 0.5).sum()} / {len(merged)} ({(merged['pct_diff'] > 0.5).mean()*100:.1f}%)\")\n",
    "\n",
    "if correlation < 0.90:\n",
    "    print(f\"\\nWarning: Low correlation ({correlation:.3f}) - Stacking diverging significantly\")\n",
    "    print(\"This likely explains the 0.0 Kaggle score\")\n",
    "elif correlation > 0.99:\n",
    "    print(f\"\\nHigh correlation ({correlation:.3f}) - Stacking barely different from fixed weights\")\n",
    "    print(\"Stacking isn't adding value\")\n",
    "else:\n",
    "    print(f\"\\nModerate correlation ({correlation:.3f}) - Stacking making adjustments\")\n",
    "\n",
    "# Show worst divergences\n",
    "print(f\"\\nTop 10 largest differences:\")\n",
    "print(merged.nlargest(10, 'abs_diff')[['id', 'new_house_transaction_amount_ensemble', \n",
    "                                        'new_house_transaction_amount_stacking', 'abs_diff']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
