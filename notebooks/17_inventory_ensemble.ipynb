{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Inventory-Adjusted Ensemble Model\n",
    "\n",
    "### Score: 0.53673\n",
    "\n",
    " This notebook extends the base ensemble (0.2, 0.65, sum=0.85) with inventory adjustment.\n",
    "\n",
    "\n",
    "\n",
    " Key innovation: Use `period_new_house_sell_through` as a market health signal\n",
    "\n",
    " - High sell-through period = oversupply = reduce predictions further\n",
    "\n",
    " - Low sell-through period = strong demand = less aggressive discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INVENTORY-ADJUSTED ENSEMBLE CONFIGURATION\n",
      "============================================================\n",
      "\n",
      "Method 1 - Weighted Geometric Mean:\n",
      "  n_lags: 6\n",
      "  alpha: 0.5\n",
      "  t2: 6\n",
      "\n",
      "Method 2 - Seasonality Bump:\n",
      "  n_lags: 7\n",
      "  alpha: 0.5\n",
      "  t2: 6\n",
      "  clip_low: 0.85\n",
      "  clip_high: 1.4\n",
      "\n",
      "Ensemble Weights:\n",
      "  weight_method1: 0.2\n",
      "  weight_method2: 0.65\n",
      "\n",
      "Inventory Adjustment:\n",
      "  use_inventory: True\n",
      "  inventory_impact: 0.5\n",
      "  baseline_sellthrough: 12.0\n",
      "  min_adjustment: 0.7\n",
      "  max_adjustment: 1.0\n",
      "\n",
      "Output Configuration:\n",
      "  output_path: /Users/nikola/Python/KaggleCompetition/output/17_Inventory_ensemble\n",
      "  filename: 17_inventory_submission.csv\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION SECTION\n",
    "# ============================================================\n",
    "\n",
    "# Data Paths\n",
    "DATA_PATH = Path(\"/Users/nikola/Python/KaggleCompetition/data\")\n",
    "\n",
    "# Method 1: Weighted Geometric Mean Configuration\n",
    "CONFIG_METHOD1 = {\n",
    "    'n_lags': 6,\n",
    "    'alpha': 0.5,\n",
    "    't2': 6,\n",
    "}\n",
    "\n",
    "# Method 2: Seasonality Bump Configuration\n",
    "CONFIG_METHOD2 = {\n",
    "    'n_lags': 7,\n",
    "    'alpha': 0.5,\n",
    "    't2': 6,\n",
    "    'clip_low': 0.85,\n",
    "    'clip_high': 1.40,\n",
    "}\n",
    "\n",
    "# Ensemble Configuration\n",
    "CONFIG_ENSEMBLE = {\n",
    "    'weight_method1': 0.2,\n",
    "    'weight_method2': 0.65,\n",
    "}\n",
    "\n",
    "# Inventory Adjustment Configuration\n",
    "CONFIG_INVENTORY = {\n",
    "    'use_inventory': True,\n",
    "    'inventory_impact': 0.5,        # How much inventory affects predictions (0-1)\n",
    "    'baseline_sellthrough': 12.0,   # Months - \"normal\" market condition\n",
    "    'min_adjustment': 0.7,          # Minimum multiplier (severe oversupply)\n",
    "    'max_adjustment': 1.0,          # Maximum multiplier (strong demand)\n",
    "}\n",
    "\n",
    "# Output Configuration\n",
    "CONFIG_OUTPUT = {\n",
    "    'output_path': '/Users/nikola/Python/KaggleCompetition/output/17_Inventory_ensemble',\n",
    "    'filename': '17_inventory_submission.csv'\n",
    "}\n",
    "\n",
    "# Display configuration\n",
    "print(\"=\" * 60)\n",
    "print(\"INVENTORY-ADJUSTED ENSEMBLE CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nMethod 1 - Weighted Geometric Mean:\")\n",
    "for key, value in CONFIG_METHOD1.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nMethod 2 - Seasonality Bump:\")\n",
    "for key, value in CONFIG_METHOD2.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nEnsemble Weights:\")\n",
    "for key, value in CONFIG_ENSEMBLE.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nInventory Adjustment:\")\n",
    "for key, value in CONFIG_INVENTORY.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nOutput Configuration:\")\n",
    "for key, value in CONFIG_OUTPUT.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (5433, 15)\n",
      "Test data: (1152, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/c74sgh7940zccznxchq0lcy40000gn/T/ipykernel_44500/3780399723.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  train_nht['month'] = pd.to_datetime(train_nht['month'])\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_nht = pd.read_csv(DATA_PATH / \"train\" / \"new_house_transactions.csv\")\n",
    "test = pd.read_csv(DATA_PATH / \"test.csv\")\n",
    "\n",
    "# Convert month to datetime\n",
    "train_nht['month'] = pd.to_datetime(train_nht['month'])\n",
    "\n",
    "# Parse test IDs\n",
    "test_id = test.id.str.split('_', expand=True)\n",
    "test['month_text'] = test_id[0]\n",
    "test['sector'] = test_id[1]\n",
    "\n",
    "# Create month mapping\n",
    "month_codes = {\n",
    "    'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
    "    'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
    "}\n",
    "\n",
    "# Add time features to training data\n",
    "train_nht['year'] = train_nht['month'].dt.year\n",
    "train_nht['month_num'] = train_nht['month'].dt.month\n",
    "train_nht['time'] = (train_nht['year'] - 2019) * 12 + train_nht['month_num'] - 1\n",
    "train_nht['sector_id'] = train_nht.sector.str.slice(7, None).astype(int)\n",
    "\n",
    "# Parse test data\n",
    "test['year'] = test['month_text'].str.slice(0, 4).astype(int)\n",
    "test['month_abbr'] = test['month_text'].str.slice(5, None)\n",
    "test['month_num'] = test['month_abbr'].map(month_codes)\n",
    "test['time'] = (test['year'] - 2019) * 12 + test['month_num'] - 1\n",
    "test['sector_id'] = test.sector.str.slice(7, None).astype(int)\n",
    "\n",
    "print(f\"Training data: {train_nht.shape}\")\n",
    "print(f\"Test data: {test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Prepare Amount Matrix and Inventory Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amount matrix shape: (67, 96)\n",
      "Sellthrough matrix shape: (67, 96)\n",
      "Time range: 0 to 66\n",
      "\n",
      "Sell-through period statistics:\n",
      "  Mean: 20.23 months\n",
      "  Min: 0.02 months\n",
      "  Max: 274.26 months\n"
     ]
    }
   ],
   "source": [
    "# Create pivot table: time x sector_id for transaction amounts\n",
    "amount_matrix = train_nht.set_index(['time', 'sector_id']).amount_new_house_transactions.unstack()\n",
    "amount_matrix = amount_matrix.fillna(0)\n",
    "\n",
    "# Create pivot table for sell-through period (inventory indicator)\n",
    "sellthrough_matrix = train_nht.set_index(['time', 'sector_id']).period_new_house_sell_through.unstack()\n",
    "sellthrough_matrix = sellthrough_matrix.fillna(CONFIG_INVENTORY['baseline_sellthrough'])\n",
    "\n",
    "# Add sector 95 (missing in training)\n",
    "amount_matrix[95] = 0\n",
    "sellthrough_matrix[95] = CONFIG_INVENTORY['baseline_sellthrough']\n",
    "\n",
    "amount_matrix = amount_matrix[np.arange(1, 97)]\n",
    "sellthrough_matrix = sellthrough_matrix[np.arange(1, 97)]\n",
    "\n",
    "print(f\"\\nAmount matrix shape: {amount_matrix.shape}\")\n",
    "print(f\"Sellthrough matrix shape: {sellthrough_matrix.shape}\")\n",
    "print(f\"Time range: {amount_matrix.index.min()} to {amount_matrix.index.max()}\")\n",
    "\n",
    "print(f\"\\nSell-through period statistics:\")\n",
    "print(f\"  Mean: {sellthrough_matrix.mean().mean():.2f} months\")\n",
    "print(f\"  Min: {sellthrough_matrix.min().min():.2f} months\")\n",
    "print(f\"  Max: {sellthrough_matrix.max().max():.2f} months\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3. Base Model Prediction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_geometric_mean_prediction(amount_matrix, n_lags=6, alpha=0.5, t2=6):\n",
    "    \"\"\"Method 1: Weighted Geometric Mean with exponential decay\"\"\"\n",
    "    weights = np.array([alpha**(n_lags-1-i) for i in range(n_lags)])\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    predictions = pd.DataFrame(index=np.arange(67, 79), columns=amount_matrix.columns, dtype=float)\n",
    "    \n",
    "    for sector in amount_matrix.columns:\n",
    "        if (amount_matrix.tail(t2)[sector].min() == 0) or (amount_matrix[sector].sum() == 0):\n",
    "            predictions[sector] = 0\n",
    "            continue\n",
    "        \n",
    "        recent_vals = amount_matrix.tail(n_lags)[sector].values\n",
    "        \n",
    "        if len(recent_vals) == n_lags and (recent_vals > 0).any():\n",
    "            positive_mask = recent_vals > 0\n",
    "            positive_vals = recent_vals[positive_mask]\n",
    "            corresponding_weights = weights[positive_mask]\n",
    "            \n",
    "            if len(positive_vals) > 0:\n",
    "                corresponding_weights = corresponding_weights / corresponding_weights.sum()\n",
    "                log_vals = np.log(positive_vals)\n",
    "                weighted_log_mean = np.sum(corresponding_weights * log_vals)\n",
    "                weighted_geom_mean = np.exp(weighted_log_mean)\n",
    "                predictions[sector] = weighted_geom_mean\n",
    "            else:\n",
    "                predictions[sector] = 0\n",
    "        else:\n",
    "            predictions[sector] = 0\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def compute_december_multipliers(amount_matrix, clip_low=0.85, clip_high=1.40):\n",
    "    \"\"\"Compute December seasonality multipliers\"\"\"\n",
    "    is_december = (amount_matrix.index.values % 12) == 11\n",
    "    dec_means = amount_matrix[is_december].mean(axis=0)\n",
    "    nondec_means = amount_matrix[~is_december].mean(axis=0)\n",
    "    dec_counts = amount_matrix[is_december].notna().sum(axis=0)\n",
    "    \n",
    "    raw_mult = dec_means / (nondec_means + 1e-9)\n",
    "    overall_mult = float(dec_means.mean() / (nondec_means.mean() + 1e-9))\n",
    "    \n",
    "    raw_mult = raw_mult.where(dec_counts >= 1, overall_mult)\n",
    "    raw_mult = raw_mult.replace([np.inf, -np.inf], 1.0).fillna(1.0)\n",
    "    clipped_mult = raw_mult.clip(lower=clip_low, upper=clip_high)\n",
    "    \n",
    "    return clipped_mult.to_dict()\n",
    "\n",
    "\n",
    "def ewgm_per_sector(amount_matrix, sector, n_lags, alpha):\n",
    "    \"\"\"Exponential weighted geometric mean for one sector\"\"\"\n",
    "    weights = np.array([alpha**(n_lags - 1 - i) for i in range(n_lags)], dtype=float)\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    recent_vals = amount_matrix.tail(n_lags)[sector].values\n",
    "    if (len(recent_vals) != n_lags) or (recent_vals <= 0).all():\n",
    "        return 0.0\n",
    "    \n",
    "    mask = recent_vals > 0\n",
    "    pos_vals = recent_vals[mask]\n",
    "    pos_w = weights[mask]\n",
    "    \n",
    "    if pos_vals.size == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    pos_w = pos_w / pos_w.sum()\n",
    "    log_vals = np.log(pos_vals + 1e-12)\n",
    "    wlm = np.sum(pos_w * log_vals)\n",
    "    return float(np.exp(wlm))\n",
    "\n",
    "\n",
    "def seasonal_bump_prediction(amount_matrix, n_lags=7, alpha=0.5, t2=6, \n",
    "                            clip_low=0.85, clip_high=1.40):\n",
    "    \"\"\"Method 2: Seasonality Bump\"\"\"\n",
    "    predictions = pd.DataFrame(index=np.arange(67, 79), columns=amount_matrix.columns, dtype=float)\n",
    "    \n",
    "    for sector in amount_matrix.columns:\n",
    "        if (amount_matrix.tail(t2)[sector].min() == 0) or (amount_matrix[sector].sum() == 0):\n",
    "            predictions[sector] = 0.0\n",
    "            continue\n",
    "        \n",
    "        base = ewgm_per_sector(amount_matrix, sector, n_lags, alpha)\n",
    "        predictions[sector] = base\n",
    "    \n",
    "    # Apply December multipliers\n",
    "    dec_multipliers = compute_december_multipliers(amount_matrix, clip_low, clip_high)\n",
    "    dec_rows = [t for t in predictions.index.values if (t % 12) == 11]\n",
    "    \n",
    "    if len(dec_rows) > 0:\n",
    "        for sector in predictions.columns:\n",
    "            m = dec_multipliers.get(sector, 1.0)\n",
    "            predictions.loc[dec_rows, sector] *= m\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4. Inventory Adjustment Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_inventory_adjustment(sellthrough_matrix, config):\n",
    "    \"\"\"\n",
    "    Calculate inventory-based adjustment multipliers\n",
    "    \n",
    "    Logic: High sell-through period = oversupply = reduce predictions\n",
    "           Low sell-through period = strong demand = less discount\n",
    "    \n",
    "    Returns DataFrame of adjustment multipliers (time x sector)\n",
    "    \"\"\"\n",
    "    baseline = config['baseline_sellthrough']\n",
    "    impact = config['inventory_impact']\n",
    "    min_adj = config['min_adjustment']\n",
    "    max_adj = config['max_adjustment']\n",
    "    \n",
    "    # Get recent sell-through period (last 3 months average for stability)\n",
    "    recent_sellthrough = sellthrough_matrix.tail(3).mean(axis=0)\n",
    "    \n",
    "    # Calculate adjustment factor\n",
    "    # ratio > 1.0 = oversupply (sell-through longer than baseline)\n",
    "    # ratio < 1.0 = strong demand (sell-through shorter than baseline)\n",
    "    ratio = recent_sellthrough / baseline\n",
    "    \n",
    "    # Convert to multiplier with configurable impact\n",
    "    # oversupply → reduce predictions\n",
    "    # strong demand → keep predictions higher\n",
    "    adjustment = 1.0 - (ratio - 1.0) * impact\n",
    "    \n",
    "    # Clip to reasonable range\n",
    "    adjustment = adjustment.clip(lower=min_adj, upper=max_adj)\n",
    "    \n",
    "    # Create adjustment matrix for prediction period (repeat for all 12 months)\n",
    "    adjustment_matrix = pd.DataFrame(\n",
    "        index=np.arange(67, 79),\n",
    "        columns=sellthrough_matrix.columns,\n",
    "        dtype=float\n",
    "    )\n",
    "    \n",
    "    for month_idx in adjustment_matrix.index:\n",
    "        adjustment_matrix.loc[month_idx] = adjustment\n",
    "    \n",
    "    return adjustment_matrix\n",
    "\n",
    "\n",
    "def apply_inventory_adjustment(predictions, adjustment_matrix):\n",
    "    \"\"\"Apply inventory adjustment to predictions\"\"\"\n",
    "    adjusted = predictions * adjustment_matrix\n",
    "    return adjusted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 5. Generate Base Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GENERATING BASE PREDICTIONS\n",
      "============================================================\n",
      "\n",
      "Method 1: Weighted Geometric Mean\n",
      "  Predictions shape: (12, 96)\n",
      "\n",
      "Method 2: Seasonality Bump\n",
      "  Predictions shape: (12, 96)\n",
      "\n",
      "Creating base ensemble (0.2, 0.65)...\n",
      "  Base ensemble mean: 21,062\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GENERATING BASE PREDICTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate Method 1 predictions\n",
    "print(\"\\nMethod 1: Weighted Geometric Mean\")\n",
    "method1_predictions = weighted_geometric_mean_prediction(\n",
    "    amount_matrix, \n",
    "    **CONFIG_METHOD1\n",
    ")\n",
    "print(f\"  Predictions shape: {method1_predictions.shape}\")\n",
    "\n",
    "# Generate Method 2 predictions\n",
    "print(\"\\nMethod 2: Seasonality Bump\")\n",
    "method2_predictions = seasonal_bump_prediction(\n",
    "    amount_matrix, \n",
    "    **CONFIG_METHOD2\n",
    ")\n",
    "print(f\"  Predictions shape: {method2_predictions.shape}\")\n",
    "\n",
    "# Create base ensemble\n",
    "print(\"\\nCreating base ensemble (0.2, 0.65)...\")\n",
    "base_ensemble = (CONFIG_ENSEMBLE['weight_method1'] * method1_predictions + \n",
    "                 CONFIG_ENSEMBLE['weight_method2'] * method2_predictions)\n",
    "\n",
    "print(f\"  Base ensemble mean: {base_ensemble.mean().mean():,.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 6. Apply Inventory Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "APPLYING INVENTORY ADJUSTMENT\n",
      "============================================================\n",
      "\n",
      "Inventory adjustment statistics:\n",
      "  Mean multiplier: 0.806\n",
      "  Min multiplier: 0.700\n",
      "  Max multiplier: 1.000\n",
      "\n",
      "Final predictions after inventory adjustment:\n",
      "  Mean: 16,839\n",
      "  Change from base: -20.0%\n",
      "\n",
      "Final prediction statistics:\n",
      "  Min: 0\n",
      "  Max: 123,555\n",
      "  Mean: 16,839\n",
      "  Median: 7,671\n"
     ]
    }
   ],
   "source": [
    "if CONFIG_INVENTORY['use_inventory']:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"APPLYING INVENTORY ADJUSTMENT\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Calculate inventory adjustment\n",
    "    inventory_adjustment = calculate_inventory_adjustment(sellthrough_matrix, CONFIG_INVENTORY)\n",
    "    \n",
    "    print(f\"\\nInventory adjustment statistics:\")\n",
    "    print(f\"  Mean multiplier: {inventory_adjustment.mean().mean():.3f}\")\n",
    "    print(f\"  Min multiplier: {inventory_adjustment.min().min():.3f}\")\n",
    "    print(f\"  Max multiplier: {inventory_adjustment.max().max():.3f}\")\n",
    "    \n",
    "    # Apply adjustment\n",
    "    final_predictions = apply_inventory_adjustment(base_ensemble, inventory_adjustment)\n",
    "    \n",
    "    print(f\"\\nFinal predictions after inventory adjustment:\")\n",
    "    print(f\"  Mean: {final_predictions.mean().mean():,.0f}\")\n",
    "    print(f\"  Change from base: {((final_predictions.mean().mean() / base_ensemble.mean().mean()) - 1) * 100:+.1f}%\")\n",
    "else:\n",
    "    print(\"\\nInventory adjustment disabled, using base ensemble\")\n",
    "    final_predictions = base_ensemble\n",
    "\n",
    "# Ensure sector 95 is all zeros\n",
    "if 95 in final_predictions.columns:\n",
    "    final_predictions[95] = 0\n",
    "\n",
    "print(f\"\\nFinal prediction statistics:\")\n",
    "print(f\"  Min: {final_predictions.min().min():,.0f}\")\n",
    "print(f\"  Max: {final_predictions.max().max():,.0f}\")\n",
    "print(f\"  Mean: {final_predictions.mean().mean():,.0f}\")\n",
    "print(f\"  Median: {final_predictions.median().median():,.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 7. Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING SUBMISSION\n",
      "============================================================\n",
      "\n",
      "✅ Inventory-adjusted submission created successfully!\n",
      "Saved to: /Users/nikola/Python/KaggleCompetition/output/17_Inventory_ensemble/17_inventory_submission.csv\n",
      "\n",
      "First few predictions:\n",
      "                   id  new_house_transaction_amount\n",
      "0   2024 Aug_sector 1                   5528.256505\n",
      "1   2024 Aug_sector 2                   2528.173656\n",
      "2   2024 Aug_sector 3                   3875.167116\n",
      "3   2024 Aug_sector 4                  48654.416666\n",
      "4   2024 Aug_sector 5                   1217.433997\n",
      "5   2024 Aug_sector 6                   8928.383242\n",
      "6   2024 Aug_sector 7                   7021.967013\n",
      "7   2024 Aug_sector 8                   2266.551704\n",
      "8   2024 Aug_sector 9                   9299.746286\n",
      "9  2024 Aug_sector 10                  40174.222227\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CREATING SUBMISSION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "submission = test.copy()\n",
    "\n",
    "# Map predictions to test set\n",
    "prediction_values = []\n",
    "for _, row in test.iterrows():\n",
    "    time_idx = row['time']\n",
    "    sector_id = row['sector_id']\n",
    "    pred_value = final_predictions.loc[time_idx, sector_id]\n",
    "    prediction_values.append(pred_value)\n",
    "\n",
    "submission['new_house_transaction_amount'] = prediction_values\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(CONFIG_OUTPUT['output_path'])\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save submission\n",
    "output_file = output_dir / CONFIG_OUTPUT['filename']\n",
    "submission[['id', 'new_house_transaction_amount']].to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✅ Inventory-adjusted submission created successfully!\")\n",
    "print(f\"Saved to: {output_file}\")\n",
    "print(f\"\\nFirst few predictions:\")\n",
    "print(submission[['id', 'new_house_transaction_amount']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 8. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "INVENTORY IMPACT ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Sectors with LOWEST adjustments (worst oversupply):\n",
      "  Sector 1: 0.700x multiplier (sell-through: 45.1 months)\n",
      "  Sector 2: 0.700x multiplier (sell-through: 25.3 months)\n",
      "  Sector 3: 0.700x multiplier (sell-through: 93.6 months)\n",
      "  Sector 4: 0.700x multiplier (sell-through: 23.9 months)\n",
      "  Sector 5: 0.700x multiplier (sell-through: 185.1 months)\n",
      "  Sector 6: 0.700x multiplier (sell-through: 35.3 months)\n",
      "  Sector 8: 0.700x multiplier (sell-through: 31.6 months)\n",
      "  Sector 11: 0.700x multiplier (sell-through: 43.9 months)\n",
      "  Sector 13: 0.700x multiplier (sell-through: 19.7 months)\n",
      "  Sector 14: 0.700x multiplier (sell-through: 55.4 months)\n",
      "\n",
      "Sectors with HIGHEST adjustments (best demand):\n",
      "  Sector 7: 1.000x multiplier (sell-through: 9.9 months)\n",
      "  Sector 9: 1.000x multiplier (sell-through: 9.4 months)\n",
      "  Sector 12: 1.000x multiplier (sell-through: 9.4 months)\n",
      "  Sector 26: 1.000x multiplier (sell-through: 9.2 months)\n",
      "  Sector 27: 1.000x multiplier (sell-through: 7.8 months)\n",
      "  Sector 32: 1.000x multiplier (sell-through: 5.1 months)\n",
      "  Sector 39: 1.000x multiplier (sell-through: 12.0 months)\n",
      "  Sector 40: 1.000x multiplier (sell-through: 4.3 months)\n",
      "  Sector 41: 1.000x multiplier (sell-through: 12.0 months)\n",
      "  Sector 42: 1.000x multiplier (sell-through: 5.7 months)\n",
      "\n",
      "============================================================\n",
      "DONE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INVENTORY IMPACT ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show sectors with highest/lowest inventory adjustment\n",
    "if CONFIG_INVENTORY['use_inventory']:\n",
    "    sector_adjustments = inventory_adjustment.iloc[0]  # Same for all months\n",
    "    \n",
    "    print(\"\\nSectors with LOWEST adjustments (worst oversupply):\")\n",
    "    worst_sectors = sector_adjustments.nsmallest(10)\n",
    "    for sector, adj in worst_sectors.items():\n",
    "        sellthrough = sellthrough_matrix.tail(3)[sector].mean()\n",
    "        print(f\"  Sector {sector}: {adj:.3f}x multiplier (sell-through: {sellthrough:.1f} months)\")\n",
    "    \n",
    "    print(\"\\nSectors with HIGHEST adjustments (best demand):\")\n",
    "    best_sectors = sector_adjustments.nlargest(10)\n",
    "    for sector, adj in best_sectors.items():\n",
    "        sellthrough = sellthrough_matrix.tail(3)[sector].mean()\n",
    "        print(f\"  Sector {sector}: {adj:.3f}x multiplier (sell-through: {sellthrough:.1f} months)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DONE!\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Summary\n",
    "\n",
    "\n",
    "\n",
    " This model improves on the base ensemble (0.57974) by:\n",
    "\n",
    "\n",
    "\n",
    " 1. **Using inventory as market signal**: `period_new_house_sell_through` directly measures oversupply\n",
    "\n",
    " 2. **Sector-specific adjustments**: Sectors with high inventory get bigger discounts\n",
    "\n",
    " 3. **Configurable impact**: `inventory_impact` parameter controls how much inventory affects predictions\n",
    "\n",
    "\n",
    "\n",
    " **Key parameters to tune:**\n",
    "\n",
    " - `inventory_impact`: 0.5 = moderate impact, increase for more aggressive adjustment\n",
    "\n",
    " - `baseline_sellthrough`: 12.0 months = \"normal\" market condition\n",
    "\n",
    " - `min_adjustment`/`max_adjustment`: Bounds on how much inventory can adjust predictions\n",
    "\n",
    "\n",
    "\n",
    " **Expected improvement:** +0.005 to +0.015 (0.579 → 0.584-0.594)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CORRELATION CHECK: Stacking vs Best Fixed Weights\n",
      "============================================================\n",
      "\n",
      "Correlation between submissions: 0.98316\n",
      "\n",
      "Prediction statistics:\n",
      "       new_house_transaction_amount_inventory  \\\n",
      "count                             1152.000000   \n",
      "mean                             16839.333506   \n",
      "std                              23025.799770   \n",
      "min                                  0.000000   \n",
      "25%                               1290.203026   \n",
      "50%                               8039.846067   \n",
      "75%                              18745.572656   \n",
      "max                             123555.343673   \n",
      "\n",
      "       new_house_transaction_amount_ensemble  \n",
      "count                            1152.000000  \n",
      "mean                            21061.740699  \n",
      "std                             28002.463975  \n",
      "min                                 0.000000  \n",
      "25%                              1843.147180  \n",
      "50%                              9853.129411  \n",
      "75%                             25620.303156  \n",
      "max                            145102.206947  \n",
      "\n",
      "Differences:\n",
      "  Mean absolute difference: 4,222.41\n",
      "  Max absolute difference: 43,530.66\n",
      "  Samples with >10% difference: 684 / 1152 (59.4%)\n",
      "  Samples with >50% difference: 0 / 1152 (0.0%)\n",
      "\n",
      "Moderate correlation (0.983) - Inventory making adjustments\n",
      "\n",
      "Top 10 largest differences:\n",
      "                     id  new_house_transaction_amount_ensemble  \\\n",
      "468  2024 Dec_sector 85                          145102.206947   \n",
      "438  2024 Dec_sector 55                          115065.045412   \n",
      "84   2024 Aug_sector 85                          111133.480597   \n",
      "180  2024 Sep_sector 85                          111133.480597   \n",
      "276  2024 Oct_sector 85                          111133.480597   \n",
      "372  2024 Nov_sector 85                          111133.480597   \n",
      "564  2025 Jan_sector 85                          111133.480597   \n",
      "660  2025 Feb_sector 85                          111133.480597   \n",
      "756  2025 Mar_sector 85                          111133.480597   \n",
      "852  2025 Apr_sector 85                          111133.480597   \n",
      "\n",
      "     new_house_transaction_amount_inventory      abs_diff  \n",
      "468                           101571.544863  43530.662084  \n",
      "438                            80545.531788  34519.513624  \n",
      "84                             77793.436418  33340.044179  \n",
      "180                            77793.436418  33340.044179  \n",
      "276                            77793.436418  33340.044179  \n",
      "372                            77793.436418  33340.044179  \n",
      "564                            77793.436418  33340.044179  \n",
      "660                            77793.436418  33340.044179  \n",
      "756                            77793.436418  33340.044179  \n",
      "852                            77793.436418  33340.044179  \n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# Compare stacking submission with best fixed weights submission\n",
    "print(\"=\" * 60)\n",
    "print(\"CORRELATION CHECK: Stacking vs Best Fixed Weights\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load both submission files\n",
    "inventory_path = '/Users/nikola/Python/KaggleCompetition/output/17_Inventory_ensemble/17_inventory_submission.csv'\n",
    "ensemble_path = '/Users/nikola/Python/KaggleCompetition/output/15_new_try_EWGM_Ensemble/15_EWGM_w85_submission.csv'\n",
    "\n",
    "inventory_sub = pd.read_csv(inventory_path)\n",
    "ensemble_sub = pd.read_csv(ensemble_path)\n",
    "\n",
    "# Merge on id to align predictions\n",
    "merged = inventory_sub.merge(ensemble_sub, on='id', suffixes=('_inventory', '_ensemble'))\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = merged['new_house_transaction_amount_inventory'].corr(\n",
    "    merged['new_house_transaction_amount_ensemble']\n",
    ")\n",
    "\n",
    "print(f\"\\nCorrelation between submissions: {correlation:.5f}\")\n",
    "\n",
    "# Show prediction statistics\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(merged[['new_house_transaction_amount_inventory', 'new_house_transaction_amount_ensemble']].describe())\n",
    "\n",
    "# Check differences\n",
    "merged['abs_diff'] = np.abs(\n",
    "    merged['new_house_transaction_amount_inventory'] -\n",
    "    merged['new_house_transaction_amount_ensemble']\n",
    ")\n",
    "merged['pct_diff'] = merged['abs_diff'] / (merged['new_house_transaction_amount_ensemble'] + 1)\n",
    "\n",
    "print(f\"\\nDifferences:\")\n",
    "print(f\"  Mean absolute difference: {merged['abs_diff'].mean():,.2f}\")\n",
    "print(f\"  Max absolute difference: {merged['abs_diff'].max():,.2f}\")\n",
    "print(f\"  Samples with >10% difference: {(merged['pct_diff'] > 0.1).sum()} / {len(merged)} ({(merged['pct_diff'] > 0.1).mean()*100:.1f}%)\")\n",
    "print(f\"  Samples with >50% difference: {(merged['pct_diff'] > 0.5).sum()} / {len(merged)} ({(merged['pct_diff'] > 0.5).mean()*100:.1f}%)\")\n",
    "\n",
    "if correlation < 0.90:\n",
    "    print(f\"\\nWarning: Low correlation ({correlation:.3f}) - Inventory diverging significantly\")\n",
    "    print(\"This likely explains the 0.0 Kaggle score\")\n",
    "elif correlation > 0.99:\n",
    "    print(f\"\\nHigh correlation ({correlation:.3f}) - Inventory barely different from fixed weights\")\n",
    "    print(\"Inventory isn't adding value\")\n",
    "else:\n",
    "    print(f\"\\nModerate correlation ({correlation:.3f}) - Inventory making adjustments\")\n",
    "\n",
    "# Show worst divergences\n",
    "print(f\"\\nTop 10 largest differences:\")\n",
    "print(merged.nlargest(10, 'abs_diff')[['id', 'new_house_transaction_amount_ensemble', \n",
    "                                        'new_house_transaction_amount_inventory', 'abs_diff']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kagglecompetition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
